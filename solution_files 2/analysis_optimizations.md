Анализ и варианты оптимизации (п. 2.3.2)

1) Индексы:
   - Убедиться, что есть индексы на order_table.order_date, order_item.nomenclature_id, order_item.order_id.
   - Индекс на order_table(client_id) уже есть.
   - Для category_closure индексы на (ancestor, depth) и (descendant, depth) ускорят выборку родительских/детских узлов.

2) Материализованные агрегаты:
   - Для нагрузки тысячи заказов в день полезно иметь агрегированные таблицы (daily_sales, sku_sales) которые обновляются частично (ETL или триггерами / background jobs).
   - Например table sku_sales(date, nomenclature_id, total_qty). Запрос топ-5 за последний месяц будет суммировать по sku_sales в нужном диапазоне — намного быстрее.

3) Denormalization:
   - В order_item хранить unit_price (уже делаем) и, при необходимости, snapshot категории верхнего уровня (category_level_1_id) для быстрого отчета без join-ов к closure.
   - Можно также хранить путь категории как текст (materialized path) для быстрых lookup'ов.

4) Выбор структуры дерева:
   - Closure table даёт гибкость и быстрые аналитические запросы, но таблица closure растёт квадратично от числа узлов в худшем случае.
   - Alternative: materialized path (varchar path) — быстрее для чтения, проще индексация; сложнее при переструктурировании ветвей.
   - Для очень большого числа категорий выбрать materialized path + GIN index на path.

5) Шардинг / partitioning:
   - Партиционирование order_table и order_item по диапазонам даты (например monthly) значительно улучшит запросы на "последний месяц" и снизит размер обрабатываемых данных.

6) Кэширование:
   - Использовать Redis для кэширования результатов топ-N отчетов с кратким TTL.

7) Технические:
   - Использовать prepared statements / connection pooling.
   - Мониторинг и объяснение запросов (EXPLAIN ANALYZE) для "горячих" запросов.

Это базовый набор рекомендаций — выбор конкретных оптимизаций зависит от реальной нагрузки и характера изменений в данных.
